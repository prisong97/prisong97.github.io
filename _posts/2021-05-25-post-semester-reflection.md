---
title:  "Post-semester Reflections"
mathjax: true
layout: post
---

The past semester was an incredibly wild ride. Everything that could have gone wrong, went terribly wrong. This included being hospitalised for a week due to a suspected medical emergency the very week I had a midterm (thank God it was a false alarm).
I was discharged the day right before the exam, and had an MC that exempted me from the assessment. I took the midterm anyway. 

Though the workload this semester was manageable, I found the experience emotionally taxing, and I was mentally all over the place, for reasons yet unknown. Hopefully I would be able to figure out soon.

Despite this struggle, I am grateful for the learning experiences that came my way! Let me first talk about the highlight of my final semester: Stochastic
Processes.

## Stochastic Processes <3 

This module was an elective I took at the Department of Engineering. Contrary to what many of my friends feel, I absolutely loved this module. There were many encounters
with concepts I had hazy memory of, and it was truly enlightening to enforce some rigour on these fuzzy intuitions. Prior to this course, I knew of Markov Chains only in the
context of MCMC sampling. I knew that Metropolis-Hastings (MH) and Gibbs Sampling fulfilled the detailed balance conditions, but I never fully appreciated its importance when trying to determine if it had a stationary
distribution. These conditions are a little strong, and are sufficient but not necessary for ensuring a unique stationary distribution exists. Now that I think about it, by having a non-zero probability of remaining in the current state,
the markov chain produced by the MH sampler is aperiodic, by design. Coupled with recurrence, this chain is effectively ergodic! Super cool! I also learnt the importance of the second largest eigenvalue in determining the rate of convergence
to the stationary distribution in question (for finite-state markov chains). Around this time, I was also reading material on the autocorrelation between MCMC draws. Though we are now looking at uncountably infinite-state markov chains, I saw that the second-largest
eigenvalue played a part in governing this too! I really wished I took this class earlier. 

This class was easily my favourite. I speak as a final year undergraduate who has taken 8 semesters of modules. It's quite unfortunate that I butchered all the assessments (and effectively this course). Besides Real Analysis, I had not been this invested in a course. Not even Machine Learning, which I also loved. I am quite sore that I would have to exercise
my S/U for this class. I really learnt a lot, including understanding what it truly means for curiosity to kill the cat. I attended a significant number of office hour sessions, so much so that I ended up befriending two classmates because they had recognised me from Prof. Vincent's webcasted sessions. I got to clarify many doubts, and also got to ask many questions that allowed me to bridge the gap across classes. I am extremely thankful that the Prof was so open to entertaining my questions. Towards the end of the semester, I chanced upon this beautiful article written by Francis Su: https://www.francissu.com/post/the-lesson-of-grace-in-teaching. I related to this article on an incredible level, because it reminded me so much of my experience in this class. I never managed to share this with Prof. Vincent (I realised I had thanked him three times prior and wouldn't want to bother him over an email with non-urgent matters), but if anyone ever asked me to relate my experience with this course, I would let this article speak on my behalf. Honestly, I would post this article on NUSmods, but the message might seem a little cryptic. 

I would not have had it another other way.  



## Geometry and the Emergence of Perspective
TBC



